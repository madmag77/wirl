import os
import asyncio
import logging
import smtplib
from datetime import datetime, timedelta, timezone
from email.message import EmailMessage
from enum import Enum
from urllib.parse import urljoin

import feedparser
import requests
from aiogram import Bot
from bs4 import BeautifulSoup
from langchain_ollama import ChatOllama
from pydantic import BaseModel, Field
import dotenv

logger = logging.getLogger(__name__)

dotenv.load_dotenv()


class ResourceType(str, Enum):
    RSS = "rss"
    WEB = "web"


class NewsResource(BaseModel):
    url: str = Field(description="Resource URL")
    type: ResourceType = Field(description="Type of the resource")


class NewsItem(BaseModel):
    title: str = Field(description="Title of the news item")
    link: str = Field(description="Link to the news item")
    published: datetime = Field(description="Publication datetime")
    summary: str = Field(description="Summary or excerpt of the item", default="")
    llm_summary: str = Field(description="Summary of the item generated by the LLM", default="")

class NewsItemLLM(BaseModel):
    title: str = Field(description="Title of the news item")
    link: str = Field(description="Link to the news item. Don't change it from the original link.")
    published: datetime = Field(description="Publication datetime")

class NewsItems(BaseModel):
    news_items: list[NewsItemLLM] = Field(description="List of news items")


def get_next_resource(
    resources: list[NewsResource] | None,
    initial_resources_to_process: list[NewsResource],
    config: dict,
) -> dict:
    resources_to_process = resources if resources else initial_resources_to_process
    if len(resources_to_process) == 0:
        return {"no_resources_to_process": True}
    resource = NewsResource(**resources_to_process.pop(0))
    return {
        "resource": resource,
        "remaining_resources": resources_to_process,
    }


def fetch_news(resource: NewsResource, config: dict) -> dict:
    days_back = config.get("days_back", 7)
    model = config.get("model")
    reasoning = config.get("reasoning", False)
    temperature = config.get("temperature", 0)
    start_date = datetime.utcnow() - timedelta(days=days_back)
    start_date = start_date.replace(hour=0, minute=0, second=0, microsecond=0, tzinfo=timezone.utc)
    end_date = datetime.utcnow() + timedelta(days=1)
    end_date = end_date.replace(tzinfo=timezone.utc)
    news_items: list[NewsItem] = []
    headers = {"User-Agent": "Mozilla/5.0"}

    try:
        if resource.type == ResourceType.RSS:
            feed = feedparser.parse(resource.url)
            for entry in getattr(feed, "entries", []):
                published_parsed = getattr(entry, "published_parsed", None) or getattr(entry, "updated_parsed", None)
                if not published_parsed:
                    continue
                published = datetime(*published_parsed[:6])
                published = published.replace(tzinfo=timezone.utc)
                if published < start_date:
                    continue
                summary = entry.get("summary", "")
                news_items.append(
                    NewsItem(
                        title=entry.get("title", ""),
                        link=entry.get("link", ""),
                        published=published,
                        summary=summary,
                    )
                )
        elif resource.type == ResourceType.WEB:
            resp = requests.get(resource.url, headers=headers, timeout=10)
            if resp.status_code == 200:
                soup = BeautifulSoup(resp.text, "html.parser")
                batch_size = 20
                llm = ChatOllama(
                    model=model,
                    temperature=temperature,
                    validate_model_on_init=True,
                    reasoning=reasoning,
                )
                llm_news_item = llm.with_structured_output(NewsItems, method="json_schema")
                for i in range(0, len(soup.find_all("a")), batch_size):
                    text = "\n\n".join(
                        f"link: {a.get('href', '')}, text: {a.get_text(' ', strip=True)}"
                        for a in soup.find_all("a")[i : i + batch_size]
                    )
                    resp = llm_news_item.invoke(
                        f"Extract news items from the following text {text}"
                    )
                    for item in resp.news_items:
                        if item.published < start_date or item.published > end_date:
                            continue
                        link = urljoin(resource.url, item.link)
                        summary = ""
                        try:
                            article = requests.get(link, headers=headers, timeout=10)
                            art_soup = BeautifulSoup(article.text, "html.parser")
                            summary = " ".join(
                                art_soup.get_text(" ", strip=True).split()
                            )
                        except Exception:
                            pass
                        news_items.append(
                            NewsItem(
                                title=item.title,
                                link=link,
                                published=item.published,
                                summary=summary,
                            )
                        )
    except Exception as e:
        logger.warning(f"Failed to parse {resource.url}: {e}")

    return {"fetched_items": news_items}


def collect_news(
    remaining_resources_to_process: list[NewsResource],
    fetched_items: list[NewsItem] | None,
    no_resources_to_process: bool,
    config: dict,
) -> dict:
    if no_resources_to_process:
        return {"is_done": True, "news_items": []}
    return {
        "is_done": len(remaining_resources_to_process) == 0,
        "news_items": fetched_items or [],
    }


def summarize_news(news_items: list[NewsItem], config: dict) -> dict:
    if not news_items:
        return {"summary": "No new items."}
    
    model = config.get("model")
    reasoning = config.get("reasoning", False)
    temperature = config.get("temperature", 0)
    
    llm = ChatOllama(
        model=model,
        reasoning=reasoning,
        temperature=temperature,
        validate_model_on_init = True,
    )
    
    for item in news_items:
        response = llm.invoke(f"Provide a summary of the following news item:\n{item}")
        summary = getattr(response, "content", str(response))
        item.llm_summary = summary

    final_summary = "\n\n".join([f"{item.title}, {item.link}, {item.published}: {item.llm_summary}" for item in news_items])
    return {"summary": final_summary}


def send_summary(summary: str, config: dict) -> dict:
    delivery_type = config.get("type", "email")
    if delivery_type == "telegram":
        token = os.environ.get("TELEGRAM_BOT_TOKEN")
        chat_id = os.environ.get("TELEGRAM_CHAT_ID")
        if not token:
            raise ValueError("TELEGRAM_BOT_TOKEN environment variable is required")
        if not chat_id:
            raise ValueError("recipient is required for telegram delivery")

        async def _send() -> None:
            bot = Bot(token=token)
            await bot.send_message(chat_id, "Here is the news digest:\n\n" + summary)
            await bot.session.close()

        asyncio.run(_send())
    else:
        smtp_server = os.environ.get("SMTP_SERVER")
        smtp_port = int(os.environ.get("SMTP_PORT", "587"))
        smtp_username = os.environ.get("SMTP_USERNAME")
        smtp_password = os.environ.get("SMTP_PASSWORD")
        from_email = os.environ.get("FROM_EMAIL")
        to_email = os.environ.get("TO_EMAIL")

        if not smtp_server:
            raise ValueError("SMTP_SERVER environment variable is required")
        if not from_email:
            raise ValueError("FROM_EMAIL environment variable is required")
        if not to_email:
            raise ValueError("recipient is required for email delivery")

        msg = EmailMessage()
        msg["Subject"] = "News Digest"
        msg["From"] = from_email
        msg["To"] = to_email
        msg.set_content("Here is the news digest:\n\n" + summary)

        try:
            with smtplib.SMTP(smtp_server, smtp_port) as server:
                server.ehlo()
                server.starttls()
                server.ehlo()
                if smtp_username and smtp_password:
                    server.login(smtp_username, smtp_password)
                server.send_message(msg)
            logger.info("Email sent successfully")
        except Exception as e:
            logger.error(f"Failed to send email: {e}")
            raise e

    return {"success": True}

